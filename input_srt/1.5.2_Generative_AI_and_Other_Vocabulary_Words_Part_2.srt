1
00:00:05,860 --> 00:00:10,060
In this course, you've downloaded some models which have been compressed enough that they can

2
00:00:10,280 --> 00:00:14,660
actually fit on a personal computer. You may hear about different kinds of compression. One method

3
00:00:14,880 --> 00:00:20,080
is called quantization. Here's a brief conceptual description of quantization. Recall that models

4
00:00:20,280 --> 00:00:24,660
have parameters, and in the case of neural networks, these are called weights. And these

5
00:00:24,680 --> 00:00:30,260
parameters store the learning and knowledge that a model gains when it's trained with data. You may

6
00:00:30,520 --> 00:00:36,160
recall that these parameters are really just numbers, and in computers, numbers like decimal

7
00:00:36,380 --> 00:00:43,760
points are typically stored as binary numbers with 32 bits. A bit is either a 0 or a 1, and on a

8
00:00:44,180 --> 00:00:50,440
computer, a bit takes up a little bit of physical space on the computer hardware, but it adds up

9
00:00:50,500 --> 00:00:55,860
when you have a lot of parameters. Quantization takes those parameters and stores them into a

10
00:00:56,240 --> 00:01:02,200
smaller amount of space, such as 16 bits or even 8 bits. When you take a model that has billions

11
00:01:02,500 --> 00:01:09,180
of parameters and convert its parameters from taking up 32 bits of space to 16 bits or 8 bits,

12
00:01:09,540 --> 00:01:14,600
you allow the model to take up less space and therefore compress the model. In this case,

13
00:01:14,940 --> 00:01:20,420
you're quantizing the model. Another method of compression is called distillation. At a

14
00:01:20,440 --> 00:01:26,620
level is taking the original model and getting it to teach a smaller model to produce outputs that

15
00:01:26,720 --> 00:01:32,140
are just like the original model. So what you can do is run inference on the original model, give it

16
00:01:32,360 --> 00:01:38,500
inputs, and then save its outputs. For example, here's a riddle. In Spain, I call myself fiery

17
00:01:38,940 --> 00:01:44,580
long neck. What am I? The model may output the Spanish word llamas, and you may recall this from

18
00:01:44,740 --> 00:01:49,460
the translation lectures in the course. With the smaller model, you give it that same input, and it

19
00:01:49,480 --> 00:01:54,160
give some output, which may not be the same, but now it has a label to compare to, which

20
00:01:54,240 --> 00:01:58,860
is the output from the original big model. And so you can effectively train this smaller

21
00:01:59,140 --> 00:02:04,440
model to behave similarly to that larger model. Yet another method of compression is called

22
00:02:04,720 --> 00:02:10,259
pruning. This is similar to the concept of cutting leaves off of a bush or a tree. Remember

23
00:02:10,619 --> 00:02:15,200
that the parameters of the models are just numbers. After a model is trained, you can

24
00:02:15,220 --> 00:02:20,240
find out which of these parameters are actually more important or less important to the performance

25
00:02:20,440 --> 00:02:24,380
of the model. The parameters that don't seem to make a big difference in how the model performs

26
00:02:24,740 --> 00:02:30,020
can be set to zero in order to effectively deactivate them. This also saves space because

27
00:02:30,320 --> 00:02:35,760
to store the number zero, you don't actually need to take up 32 bits for every parameter that you

28
00:02:35,880 --> 00:02:42,720
know will always be zero. Another term you'll hear a lot about in the news is GPU. Every computer has

29
00:02:42,740 --> 00:02:48,180
something called a CPU, a central processing unit. And this actually runs the computer,

30
00:02:48,620 --> 00:02:53,060
kind of like the brain of the computer. And computers can also have an added piece of hardware

31
00:02:53,380 --> 00:02:58,560
called a GPU, a graphics processing unit. It's really good at performing math operations

32
00:02:59,220 --> 00:03:04,440
in parallel. So GPUs are really good for producing graphics, which is why they were initially used

33
00:03:04,640 --> 00:03:09,680
for running video games on computers. And because machine learning training is actually a lot of

34
00:03:09,700 --> 00:03:15,780
multiplication and addition, GPUs make it possible to perform machine learning training of models

35
00:03:16,160 --> 00:03:21,860
as well as inference. So when a CPU picks up a task that requires a lot of math operations,

36
00:03:22,320 --> 00:03:29,040
it can delegate that task to the GPU because the GPU can perform that task much faster and at a

37
00:03:29,160 --> 00:03:34,240
higher volume. A hot topic among businesses that wish to make use of large language models is

38
00:03:34,460 --> 00:03:39,660
called retrieval augmented generation. Let's first talk about some issues that led to the need for

39
00:03:39,680 --> 00:03:44,540
retrieval augmented generation. Recall that large language models can hallucinate. For example,

40
00:03:44,960 --> 00:03:49,760
you can ask it about yourself and it might make up something that's not true, even though it would

41
00:03:49,860 --> 00:03:55,100
be lovely if it were true. Another issue for businesses is that employees at a company may

42
00:03:55,220 --> 00:04:00,480
want to ask questions about the company's internal documents and processes. A large language model

43
00:04:00,760 --> 00:04:05,120
that's trained on public data would not have been trained on this private company information.

44
00:04:05,580 --> 00:04:11,100
For example, an employee at a company may want to ask how to operate one of the company's products.

45
00:04:11,580 --> 00:04:15,440
A large language model would not be able to give a very specific answer about it.

46
00:04:15,680 --> 00:04:22,860
Also recall that any chatbot has a context window that is limited to how much text you can give the model for any single prompt.

47
00:04:23,360 --> 00:04:27,240
So you can't just give a chatbot all the documents to let it sort through them.

48
00:04:27,640 --> 00:04:28,460
There's just not enough space.

49
00:04:28,860 --> 00:04:32,120
Now there are models that can take in a lot of text at one time,

50
00:04:32,380 --> 00:04:38,180
But an LLM would probably still perform better if you gave it the text that is most relevant to the task.

51
00:04:38,640 --> 00:04:42,140
Otherwise, it's just TMI, or too much information.

52
00:04:42,560 --> 00:04:48,060
So there's a need to find relevant documents and retrieve the relevant parts of those documents

53
00:04:48,600 --> 00:04:51,080
to help a large language model answer these kinds of questions.

54
00:04:51,600 --> 00:04:54,820
Here's a brief look at how retrieval augmented generation works.

55
00:04:55,060 --> 00:04:58,900
You have a large language model, and you also have something called a vector database.

56
00:04:59,460 --> 00:05:05,020
When you see the word vector, you can just think a long list of numbers, and you'll see why it's

57
00:05:05,240 --> 00:05:10,200
called a vector database in a bit. If you ask a large language model a question, like who is

58
00:05:10,300 --> 00:05:15,680
Eddie Xu, before the large language model answers, it first goes to a vector database, which has

59
00:05:15,820 --> 00:05:20,940
stored a bunch of information about that particular topic that you're likely to ask about. This vector

60
00:05:21,120 --> 00:05:26,000
database does a similarity search. This means that it converts the query into a list of numbers.

61
00:05:26,540 --> 00:05:29,120
Similarity search can apply to text as well.

62
00:05:29,520 --> 00:05:33,320
You may call from the lecture on similarity search that this list of numbers hold some

63
00:05:33,600 --> 00:05:37,540
descriptive meaning about the object that is describing, and is called an embedding.

64
00:05:37,780 --> 00:05:42,660
The vector database may have stored some relevant documents, such as a resume or dating profile.

65
00:05:43,100 --> 00:05:45,900
These documents have been broken up into smaller chunks of text,

66
00:05:46,360 --> 00:05:48,540
which also have embeddings calculated for them.

67
00:05:48,900 --> 00:05:54,200
So the vector database finds chunks of text that are similar to the query based on those embeddings,

68
00:05:54,420 --> 00:05:59,620
and might be relevant to answering that query. This retrieved text might look like these pieces

69
00:05:59,840 --> 00:06:05,300
of text here. This text is then sent to the LLM so that the model is able to answer the questions

70
00:06:05,860 --> 00:06:10,880
based on the retrieved text. The act of retrieving information that can be considered a source of

71
00:06:11,120 --> 00:06:16,960
truth to help a model answer a question truthfully is called grounding the model, as in grounding

72
00:06:17,140 --> 00:06:22,839
the model in facts or factual information. Yet another approach to giving large language models

73
00:06:22,860 --> 00:06:27,700
domain-specific information is fine-tuning. You heard about instruction tuning earlier,

74
00:06:28,180 --> 00:06:33,160
and more generally, fine-tuning is training a model on additional data to give it knowledge

75
00:06:33,700 --> 00:06:37,740
about a specific subject area, or also to modify its behavior in other ways,

76
00:06:38,060 --> 00:06:43,440
such as changing its tone or wording, or training it to handle sensitive topics safely. Normally,

77
00:06:43,560 --> 00:06:47,879
you start with the pre-trained model, also called a base model. It goes through an additional

78
00:06:47,900 --> 00:06:52,920
training process called fine-tuning, and the result is a fine-tuned model. So let's look at

79
00:06:53,040 --> 00:06:58,960
this in more detail. The base model was trained on a huge dataset of unlabeled text. If asked a

80
00:06:59,240 --> 00:07:03,900
domain-specific question, it won't know the answer. So you send the model through a fine-tuning process.

81
00:07:04,440 --> 00:07:10,200
For this model, you give it curated labeled data. For instance, for a given input like this,

82
00:07:10,580 --> 00:07:17,860
your training data also has examples of correct output, such as this or this. So you send this

83
00:07:17,880 --> 00:07:22,900
the model, it outputs something that probably isn't quite right yet. And I'm simplifying the

84
00:07:23,040 --> 00:07:27,960
next few steps a bit, but you can send the model's outputs and the labels, the examples of the correct

85
00:07:28,180 --> 00:07:33,640
acceptable outputs, to a performance measure which an optimizer uses to update the model's parameters.

86
00:07:34,020 --> 00:07:38,180
After you've done fine-tuning with this domain-specific dataset, you get a fine-tuned model.

87
00:07:38,640 --> 00:07:43,620
So now, when you ask it domain-specific questions like this, it will output some useful information

88
00:07:43,660 --> 00:07:48,840
that it learned from the fine-tuning process. Another word you may hear lately in the news about

89
00:07:49,140 --> 00:07:54,580
AI are agents. People are still deciding what is the actual definition of an agent, but generally

90
00:07:54,940 --> 00:07:59,180
they appear to be attempts at making applications that can make decisions and take actions

91
00:07:59,500 --> 00:08:04,440
independently without needing much supervision from people. So far, agents are large language models

92
00:08:04,860 --> 00:08:10,080
that are wrapped in additional code to make them so-called agents. And here are some properties of

93
00:08:10,100 --> 00:08:15,480
agents. One is reflection, which you may recall from this course. Instead of having a user ask

94
00:08:15,580 --> 00:08:20,980
the large language model if they're sure, or asking the LLM to review their own work, an agent already

95
00:08:21,160 --> 00:08:27,960
has this built in, so that it will ask itself, am I sure? Or, let me review my work. Another feature

96
00:08:28,100 --> 00:08:32,760
of agents is tool use, which you might recall from this course. It's the ability to take actions

97
00:08:33,120 --> 00:08:38,180
beyond just outputting text, and some examples would be calling a web search or opening up a

98
00:08:38,200 --> 00:08:42,860
calendar, and it could potentially be any other software application. Another aspect of agents is

99
00:08:42,979 --> 00:08:48,280
planning, or the ability to think through a multi-step process. For instance, an agent that plays the

100
00:08:48,420 --> 00:08:52,160
role of a travel agent might be able to think through the steps that it might take when it's

101
00:08:52,300 --> 00:08:56,900
helping a customer with their vacation plans. For instance, first get a customer's vacation

102
00:08:57,240 --> 00:09:02,600
preferences, then search for possible destinations that match those preferences, then search for

103
00:09:02,880 --> 00:09:08,160
airline flights, and then book those flights. The idea is that an agent would first plan out a

104
00:09:08,180 --> 00:09:13,040
process and then follow through on that multi-step process. And another aspect of agents is

105
00:09:13,300 --> 00:09:18,300
collaboration. You saw a little bit of this in the chatbot to chatbot collaboration part of the

106
00:09:18,520 --> 00:09:23,500
course, where you were an intermediary between one large language model who was the writer and

107
00:09:23,660 --> 00:09:27,900
another large language model who was the editor. When you wrap each of these large language models

108
00:09:28,140 --> 00:09:32,960
with code to make them more autonomous or to make them agents, so to speak, then the two can

109
00:09:33,260 --> 00:09:37,940
collaborate fairly autonomously and you can sort of step back a little bit and maybe have a snack.

110
00:09:38,340 --> 00:09:41,440
And so you might hear this being referred to as multi-AI agents.

111
00:09:42,420 --> 00:09:43,820
So that was a lot of information.

112
00:09:44,400 --> 00:09:48,060
You can sort of treat this more as a reference for you to look back on when you're reading

113
00:09:48,300 --> 00:09:49,880
articles and doing your own learning.

114
00:09:50,360 --> 00:09:54,640
And if you would like a more thorough explanation of any of these topics in an upcoming course,

115
00:09:55,100 --> 00:09:57,660
then please feel free to let us know in the review comments.

116
00:09:58,140 --> 00:10:02,760
Next, before we move on to the open-ended project, there's an optional discussion about

117
00:10:03,200 --> 00:10:07,180
skill stacking, which is how you can approach thinking about how you can combine your skills

118
00:10:07,280 --> 00:10:12,380
in a way to make you stand out. I'll see you in the next video or in the open-ended project.

